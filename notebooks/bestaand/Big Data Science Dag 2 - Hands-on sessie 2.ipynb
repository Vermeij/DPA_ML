{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning sessie\n",
    "In deze sessie gaan we kijken naar hoe we echte machine learning doen in Python. We maken hiervoor extensief gebruik van de scikit-learn en numpy packages.\n",
    "\n",
    "## Het vergelijken van regressiealgoritmes\n",
    "We gaan als eerste kijken naar het toepassen van lineaire regressie op de `baseball` dataset. We pakken `hr` (aantal homeruns) als afhankelijke variabele: dit is de variabele die we willen voorspellen op basis van de onafhankelijke features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd                \n",
    "import numpy as np \n",
    "from pydataset import data\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We hebben de data al voor jullie gepreprocessed en opgeslagen als CSV. Deze lezen we hier in.\n",
    "df_baseball = pd.read_csv('baseball_processed.csv', index_col=0)\n",
    "\n",
    "# We verwijderen de tekstkolommen. Deze kunnen informatief zijn, maar zouden dan eerst omgezet moeten worden naar dummy variabelen. Dat doen we nu om er wat sneller doorheen te gaan even niet.\n",
    "df_baseball.drop('team', 1, inplace=True)\n",
    "df_baseball.drop('lg', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# De dataset is al geschaald, dat hoeven we nu dus niet weer te doen.\n",
    "# We verwijderen de afhankelijke variabele uit de set\n",
    "df_baseball_X = df_baseball.drop('hr', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We splitten onze dataset in een training set en een test set, anders kunnen we niet goed evalueren hoe ons model het doet\n",
    "random_indices = np.random.permutation(len(df_baseball))\n",
    "training_indices = random_indices[:int(0.9*len(df_baseball))]\n",
    "test_indices = random_indices[int(0.9*len(df_baseball)):]\n",
    "\n",
    "df_baseball_train_X = df_baseball_X.iloc[training_indices]\n",
    "df_baseball_train_y = df_baseball.iloc[training_indices]['hr']\n",
    "\n",
    "df_baseball_test_X = df_baseball_X.iloc[test_indices]\n",
    "df_baseball_test_y = df_baseball.iloc[test_indices]['hr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Geef de gestandaardiseerde features mee als X input, en de originele hr kolom als Y labels.\n",
    "regr.fit(df_baseball_train_X, df_baseball_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.15459703437 homeruns\n"
     ]
    }
   ],
   "source": [
    "# Het model is getraind, nu kunnen we predictions maken en een score bekijken\n",
    "predictions = regr.predict(df_baseball_test_X)\n",
    "error = np.sqrt(mean_squared_error(df_baseball_test_y, predictions))\n",
    "\n",
    "print \"RMSE: {} homeruns\".format(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als we random zouden voorspellen zouden we ongeveer de standaarddeviatie krijgen als score. We kijken wat de standaarddeviatie is van de homerun-kolom en vergelijken dit met de RMSE van ons model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    21634.000000\n",
       "mean         5.248035\n",
       "std          8.792642\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          7.000000\n",
       "max         73.000000\n",
       "Name: hr, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseball['hr'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De mean is 5.24 en de standaarddeviatie is 8.79. De RMSE van ons model is ongeveer 2.9. Het lijkt er dus op dat ons model beter dan random kan voorspellen wat het aantal homeruns is. Het is interessant om de coefficienten te bekijken van ons model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year' 'g' 'ab' 'r' 'h' 'X2b' 'X3b' 'rbi' 'sb' 'bb' 'so' 'hbp' 'sh']\n",
      "[ 0.02398466 -0.00462389 -0.0164644   0.14833557 -0.02268024 -0.14975706\n",
      " -0.40005629  0.24245113 -0.116909    0.00548037  0.09825346 -0.04188937\n",
      " -0.14128875]\n",
      "-47.6566875922\n"
     ]
    }
   ],
   "source": [
    "print df_baseball_train_X.columns.values\n",
    "print regr.coef_\n",
    "print regr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hieruit kunnen we opmaken welke inputvariabele op welke manier effect heeft op de zuinigheid van auto's. Zo zien we bijv. dat de variabele 'r' een groot positief effect heeft gehad op het aantal homeruns.\n",
    "\n",
    "## Geavanceerdere methodes\n",
    "Lineaire regressie is een erg simpele manier om dit op te lossen. Als er een niet-lineair verband is tussen een feature en het aantal homeruns wordt dat door dit model niet opgepakt. Ook zijn er misschien features die helemaal niet belangrijk zijn voor het model. Dat laatste kunnen we oplossen door regularisatie te gebruiken. Dit kan gemakkelijk in scikit-learn door de Ridge module te gebruiken in plaats van LinearRegression. Doe dit, en vergelijk het resultaat. Wat gebeurt er met de coefficienten als je de alpha parameter verhoogt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals al eerder verteld is een lineair model erg simpel. Een algoritme dat vaak beter werkt is een random forest. Deze kun je in scikit-learn vinden in ensemble.RandomForestRegressor. Gebruik deze module en vergelijk je resultaat met dat van een lineair model. Kijk ook wat je aan hyperparameters van het algoritme kunt aanpassen om een beter resultaat te krijgen en kijk wat volgens het algoritme de 'belangrijkheid' is van de verschillende features. Wat valt op?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificatie\n",
    "Voor classificatie pakken we een andere dataset: .... We gaan eerst classificatie uitvoeren met een simpele logistische regressie, en kjiken vervolgens naar wat geavanceerdere technieken.\n",
    "\n",
    "Laad de dataset in, bekijk welke kolommen je allemaal nodig hebt en welke je wilt voorspellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code hier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maak vervolgens een logistic regression classifier die een classificatie kan uitvoeren op de afhankelijke variabele. Split je train en test sets door middel van 10-fold cross-validation (tip: gebruik de KFold module in scikit-learn). Evalueer je methode met accuracy, precision en recall (tip: gebruik een functie om de confusion matrix te berekenen, daar kun je makkelijk de benodigde statistieken uithalen). Maak ook een Precision/Recall-curve en bereken de oppervlakte daaronder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code hier"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python3]",
   "language": "python",
   "name": "Python [python3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
